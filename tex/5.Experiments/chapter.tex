\expandafter\ifx\csname MasterFile\endcsname\relax
\def\SubFile{hoge}
\input{../thesis/thesis}
\begin{document}
\setcounter{chapter}{4}
\fi
%-------------------------------------------------------------------------------
\cleardoublepage
\chapter{評価実験}
\label{exp:chapter}

\section{序言}
\label{exp:introduction}
本章では，COLLAGREEで行われた議論のデータを対象にした提案手法の評価実験について述べる．
評価実験ではCOLLAGREE上で行われた複数の議論データを用意し，提案手法と比較手法で実験を行う．結果として提案手法のほうが分散表現を用いていることで良い精度を出せるか確認する．\\
%評価実験ではネットワークの種類を複数用意し, 提案手法と既存手法の比較を行う. 結果として電力ネットワークの特徴を用い送電ロスを抑制ができているかを確認する.
以下に本章の構成を述べる．まず，\ref{exp:data}節では実験に用いたデータについて説明する．\ref{exp:setting}節では実験設定について述べ，\ref{exp:result}節では評価実験の結果を示す．\ref{exp:consideration}節では実験結果に対する考察を行い，最後に\ref{exp:conclusion}節で本章のまとめを示す．

\clearpage
\section{対象データ}
\label{exp:data}
\subsection{議論データ}
\label{exp:data:discussion}
議論データはCOLLAGREEを用いた実験で収集されたデータを使用する．データの概要を以下に示す．
\\
\noindent{\bf【実験概要】}
\begin{description}
\item [実施年月]：2017年3月
\item [グループ人数]：2$\sim$3名
\item [議論時間]：90分前後
\item [議論テーマ]：外国人観光客向けの日本旅行プランの決定
\item [議論テーマ説明文]：みなさまに、外国人観光客向けの日本旅行プランを立てていただきます。 想定される旅行者の条件は以下の通りです。
\begin{itemize}
\item 英語は話せるが、日本語は話せない
\item 初めての日本旅行である
\item 日程は6泊7日
\item ホテルは自分たちで手配できる
\item 旅行のために貯金したので、金銭的には余裕があり、国内をいろいろとまわることが可能である
\item 来日、帰国の際の空港は、どこでもかまわない
\item ２つのプランを比較したいと考えている（プランは２つ用意してください）
\end{itemize}
\item [ファシリテータ]：あり
\end{description}

\subsection{評価データ}
\label{exp:data:evaluation}
本研究では \ref{exp:data:discussion}節で説明した議論データに対し，次に述べる基準で伊藤孝行研究室の学生にアノテーションを行ってもらった．アノテーション担当者が基準を満たすと判断した発言に"1"のタグを，満たすと思われない発言に"0"のタグを付ける．
\subsubsection*{\circled{1} それまで話題となっていた対象や事態とは異なる，新しい対象や事態への言及する発言}
話されている内容が，以前と全く異なる対象や事態へと移行する位置でデータを区切る．
\paragraph{例1:}\ \\
(今までの話題:パック旅行はなぜ安いのかについて)
\begin{itemize}
\item A:ホテルが宿泊費の一部を出しているから安いのかな？
\item B:おそらく。
\item A:なるほど。
\item B:\underline{沖縄行きも安いね。}(今まで沖縄の話はされておらず，この後“沖縄行きのパック旅行”に話題が変わる(かもしれない))
\end{itemize}
\paragraph{例2:}\ \\
(今までの話題:外国人のツアー旅行の行き先について)
\begin{itemize}
\item A:\underline{他は寄らなくてもよいですか？}(新しい行き先が出るように仕向けている)
\end{itemize}

 \subsubsection*{\circled{2} 既に言及された対象や事態の異なる側面への言及する発言}
既に話題として取り上げられることについて，以前とは異なる側面から言及がなされる位置で区切る．
\paragraph{例3:}\ \\
(今までの話題:外国人のツアー旅行の行き先について)
\begin{itemize}
\item A:広島、長崎はどう？
\item B:外国人観光客とか広島、長崎で見かけた覚えないな。
\item A:\underline{ツアーに英語を話せるスタッフとか付けられるかな？}(“ツアー旅行のスタッフ”に話題が変わる(かもしれない))
\end{itemize}

 \subsubsection*{\circled{3}議論のフェーズを移行させる(かもしれない)発言}
議論のフェーズを今までから移行させる(と思われる)発言の位置で区切る．
\paragraph{例4:}\ \\
(今までの話題:外国人のツアー旅行の行き先について)
\begin{itemize}
\item A:八坂神社や清水寺など有名どころがたくさんありますし、魅力的だと思います
\item B:\ulinej{京都周辺ツアー 清水寺、金閣寺、銀閣寺、伏見稲荷大社、嵐山、など日本の建物や食べ物など広島長崎ツアー 広島、長崎の戦争の地を見る事と、それぞれの場所で食べ物建造物を見るツアー}(地名を挙げる段階から，各地点を結ぶツアープランへの作成段階に話題が変わる(かもしれない)．)
\end{itemize}

\paragraph{例5:}\ \\
(今までの話題:外国人のツアー旅行のプランについて)
\begin{itemize}
\item A:京都周辺ツアー
 清水寺、清水焼体験、抹茶・和菓子など体験、きもの体験、金閣寺、嵐山、伏見稲荷大社
 その中で乗れそうなら屋形船などはどうでしょうか?
\item B:屋形船、風情があって良いと思います。
\item (途中省略)
\item C: \ulinej{まとめると、
 ・京都周辺ツアー
 京都周辺（八坂神社、清水寺、金閣寺、銀閣寺、伏見稲荷大社、嵐山、有馬温泉）、おいしい料理（豆腐など）、温泉、6泊7日ツアー}
 \\
 \ulinej{
 ・広島長崎ツアー
 広島（3日）：広島の原爆ドーム、平和記念公園、厳島神社、もみじまんじゅう、牡蠣、広島の筆（メイクや書道なので使用する）、お好み焼き、呉の戦艦、アナゴ
 （移動1日）
 長崎（3日）：ハウステンボス、グラバー園、眼鏡橋、大浦天主堂、軍艦島、長崎ちゃんぽん、佐世保バーガー}
 \\
 \ulinej{
 この2プランで問題ないでしょうか？}(初めて，２つのツアーの内容をまとめ，議論の収束に近づけた．)
 \end{itemize}
また，ファシリテーターによる議論をコントロールするような発言も含む．
\paragraph{例6:}\ \\
\begin{itemize}
\item F:もし現在の旅先候補でよろしければ、具体的なプランづくりに移行したいと思います。
 よろしいでしょうか？
\item F:残り20分を切りました。
 皆様、いかがでしょうか？
\end{itemize}
以上の基準に沿ってタグを付けてもらい，"1"のタグが過半数より多く付けられた発言を正解値=1，他を正解値=0とした．

\section{実験設定}
\label{exp:setting}
\subsection{パラメーター}
本実験ではパラメーターは次の通りに設定した．前処理にて用いるokapiBM25のパラメーターはk1=2, b=0.75とし，LexRankのパラメーターはn=50，threshold=0.7とした．また，重み付けを用いて文章から抽出する単語の数は5個とした．
分散表現として用いるfastTextは次元数を100次元とし，学習データにはwikipediaダンプデータを用いた．
総合類似度の計算に用いるパラメーターはmaxTime=5400(90分)，tWeight = 0.5とし，総合類似度の閾値は0.8とした．
表5.1 に実験の設定をまとめる.
\begin{table}[htbp]
\begin{center}
  \begin{tabular}{| c | c |  c |} \hline
      & k1 &  2 \\ \cline{2-3}
    okapiBM25 & b & 0.75 \\ \cline{2-3} \hline
     & n &  50 \\ \cline{2-3}
    LexRank & threshold & 0.7 \\ \cline{2-3} \hline
     \multicolumn{2}{|c|}{抽出単語数} & 5 \\  \hline
     & 次元 &  100 \\ \cline{2-3} 
    fastText & 学習データ & wikipediaダンプデータ \\ \cline{2-3} \hline
     \multicolumn{2}{|c|}{maxTime} & 5400 \\  \hline
     \multicolumn{2}{|c|}{tWeight} & 0.5 \\  \hline
     \multicolumn{2}{|c|}{類似度閾値} & 0.8 \\  \hline
  \end{tabular}
  \caption{パラメーターの設定}
  \label{table:par}
  \end{center}
\end{table}

okapiBM25のパラメーターは一般的に妥当とされる\cite{infoRetrieval}ものを用いた．LexRankのパラメーターの場合，nは50以上でも結果に差がなかったことから50とし，thresholdは結果が最も良かったものを用いた．抽出単語数も同様に最も結果が良かったものを用いた．

\subsection{比較手法}
\subsubsection*{\circled{1} 常時通知}
%最も単純かつ分かりやすい比較手法として，発言の内容に関係なく常に通知を行う手法を用いる．
１つ目の比較手法は，最も単純でわかりやすい発言の内容に関係なく常に通知する手法を用いる．
\subsubsection*{\circled{2} TF-IDFベクトル}
単語の意味は考慮せず出現頻度に基づく比較手法として，分散表現の代わりにTF-IDFで発言をベクトル化する手法を用いる．\\
２つ目の比較手法ではokapiBM25の代わりにTF-IDFを用いて連想配列を作成する．そして，連想配列から単語の重みを要素として持つベクトルに変換する．発言内容の類似度計算は提案手法と同じでCosine類似度を用い，以降の総合類似度も提案手法と同じである．

\subsection{評価指標}
本実験では評価指標として適合率(Precision)，再現率(Recall)，F値(F-measure)の３種類の指標を用いる．\\
適合率，再現率，F値はそれぞれ次のようにして求める．まず，発言の通知を行うと判定した時を予測値=1，通知を行わないと判定した時を予測値=0とする．次に，予測値=1かつ正解値=1であるものの個数を$TP(True~Positive)$または$hits$(的中数)，予測値=0かつ正解値=1であるものの個数を$FP(False~Negative)$または$misses$(見逃し数)，予測値=1かつ正解値=0であるものの個数を$FP(False~Positive)$または$falseAlarms$(誤警報数)として数える．また，予測値=0かつ正解値=0であるものの個数を$TN(True~Negative)$として数える．そして，式\ref{eq:Precision}，式\ref{eq:Recall}及び式\ref{eq:F-measure}に従って適合率，再現率，F値を計算する．
\begin{equation}
\begin{aligned}
\label{eq:Precision}
Precision & = \frac{hits}{hits+falseAlarms}
\end{aligned}
\end{equation}
%
\begin{equation}
\begin{aligned}
\label{eq:Recall}
Recall & = \frac{hits}{hits+misses}
\end{aligned}
\end{equation}
%
\begin{equation}
\begin{aligned}
\label{eq:F-measure}
F-measure & = \frac{2 \cdot Precision \cdot Recall}{Precision+Recall}
\end{aligned}
\end{equation}

３つの値はどれも値が高いほど判定精度が高いことを示す．

\section{実験結果}
\label{exp:result}
実験結果を表\ref{table:result}に示す．
\begin{table}[htb]
\begin{center}
  \begin{tabular}{| c | c | c | c |} \hline
    手法 & \multicolumn{3}{| c |}{平均評価指標} \\ \cline{2-4}
     & Precision & Recall & F-measure \\ \hline \hline
    比較手法1 &0.256579335 & 1 & 0.404074977 \\ \hline
    比較手法2 &0.75 & 0.105429708 & 0.180947229 \\ \hline
    提案手法 &0.517148273 & 0.558192262 & 0.509950195 \\ \hline
    \end{tabular}
    \caption{実験結果}
    \label{table:result}
\end{center}
\end{table}

また，各手法のTP,TN,FP,FNの割合の平均，及びTPとFPの平均割合の和であるP-SUMとTNとFNの平均割合の和であるN-SUMを表\ref{table:result2}に示す．
\begin{table}[htb]
\begin{center}
  \begin{tabular}{| c | c | c | c | c | c | c |} \hline
    手法 & \multicolumn{6}{| c |}{平均割合} \\ \cline{2-7}
     & TP & TN & FP  & FN & P-SUM & N-SUM \\ \hline \hline
    比較手法1 &0.251993 & 0 & 0.748006 & 0 &1.0 & 0 \\ \hline
    比較手法2 &0.0239234 & 0.730462 & 0.0079744 & 0.2280701 & 0.0414673 & 0.9585326\\ \hline
    提案手法 &0.1419457 & 0.5980861 & 0.1499202 & 0.1100478  & 0.2918660 & 0.7081339 \\ \hline
    \end{tabular}
    \caption{実験結果2}
    \label{table:result2}
\end{center}
\end{table}

\section{考察}
\label{exp:consideration}
実験結果から次のことが言える．\\
\begin{description}
  \item[考察1] 提案手法は適合率と再現率の良いバランスで判定をすることができる
  \item[考察2] 提案手法の精度は重み付けに依存する
\end{description}
\subsection*{考察\circled{1} 提案手法は適合率と再現率の良いバランスで判定をすることができる}
表\ref{table:result}が示すように，提案手法は比較手法よりも高いF値を出している．
原因を究明するために，他２つの比較手法の問題点を考える．
比較手法1は常に話題が変化したと判定するため見逃しが無く再現率が高いが，対価として何も除外しないので適合率は低くなってしまう．極端さがF値の低下に繋がったと言える．\\
一方，比較手法2ではTF-IDFによる発言ベクトルを用いて発言内容の類似度を計算しているが，TF-IDFでは文字の出現頻度のみを使用していることと全ての単語を発言ベクトルに含んでいることから新しく投稿された発言の内容文と過去の発言の内容文の両方に同じ単語が含まれている程，類似度が大きくなる．すなわち，過去の発言に全く登場していない新しい単語を多く含んだ内容文を持つ発言でない限り，過去の発言と同じ話題であると判定されやすい．
結果として，比較手法２では過去の発言との差がよほど顕著な発言でない限り，話題が変化したと判定しなくなるため適合率は高くなるが，対価として見逃しが増え再現率が低くなる．事実，表\ref{table:result2}が示すように比較手法2では比較手法1とは逆に発言の殆どが話題の変化を起こさないものとして判定されている．図\ref{Fig:GraphTF-IDF}に比較手法２で発言の繋がりを図示したものの拡大図を示す．\\
\begin{figure}[htbp]
 \begin{center}
  \includegraphics[width=\textwidth]{../images/5.Experiment/Graph=TF-IDF2.png}
  \caption{比較手法２による繋がりグラフ-拡大図}
  \label{Fig:GraphTF-IDF}
  \vspace{-10pt}
 \end{center}
\end{figure}
図\ref{Fig:GraphTF-IDF}で示されるように殆どの発言がかなりの数の発言と同じ話題であると判定されていることが確認できる．

以上の２つの比較手法の問題点に対する考察を踏まえて提案手法が比較手法と異なる点を考える．異なる点として，上位の単語のみを類似度計算に用いている点と分散表現を用いている点が挙げられる．
比較手法2と違って，上位の単語のみが用いられることで同じ単語が含まれているだけでは類似度が上がるとは限らなくなり，結果として話題が変化したと判定する回数が増え比較手法2よりも高い再現率を示したと考えられる．
図\ref{Fig:GraphFastText}に提案手法で発言の繋がりを図示したものを示す．
\begin{figure}[htbp]
 \begin{center}
  \includegraphics[width=1.1\textwidth]{../images/5.Experiment/Graph=FastText-min.png}
  \caption{提案手法による繋がりグラフ}
  \label{Fig:GraphFastText}
  \vspace{-10pt}
 \end{center}
\end{figure}

図\ref{Fig:GraphTF-IDF}とは違い，１つの発言に対して同じ話題であると判断された発言の数は少なく，比較手法2に比べ類似度が低くなっていることが伺える．
また，分散表現を用いることで字面の異なる単語でも類似性を示すことができるため，再現率と共に適合率を上昇させることに繋がったと考えられ，故に適合率と再現率の間に大きな差を生むこと無く判定をすることができたと考えられる．

\subsection*{考察\circled{2} 提案手法の精度は重み付けに依存する}
表\ref{table:FalseAlarmsRemark}，{table:MissesRemark}にそれぞれ$falseAlarms$，$misses$となった発言の例を示す．
\begin{table}[htbp]
  \begin{tabular}{| c |  p{6cm} | p{5cm} |} \hline
     title & body  & 抽出単語 \\ \hline
     まずは旅先候補を&まずは旅先候補をどんどんお願いします。&どんどん,お願い,書き込み,皆様\\ \hline
     NULL &八坂神社、清水寺、金閣寺、銀閣寺、伏見稲荷大社、嵐山、有馬温泉 今あがっているのは、このぐらいでしょうか？&あがっ,今,伏見稲荷大社,嵐山,有馬温泉\\
     \hline
  \end{tabular}
  \caption{falseAlarms発言データ} \label{table:FalseAlarmsRemark}
\end{table}
\begin{table}[htbp]
\begin{center}
  \begin{tabular}{| c | p{8cm} | p{6cm} |} \hline
     title & body & 抽出単語 \\ \hline
     NULL&やはり東京は人気ですよね、アキバ行きたいって外国のかたが多いイメージです & 外国,行き,多い,イメージ,アキバ \\ \hline
     NULL &  \shortstack{1日目大阪（USJ）\\
 2日目京都 （大原，嵐山，金閣寺，二年坂）\\
 3日目京都 （大原，嵐山，金閣寺，二年坂）\\
 4日目金沢\\
 5日目金沢\\
 6日目箱根\\
 7日目東京\\
 と言う感じでしょうか} & 金沢,金閣寺,二年坂,大原,嵐山\\
     \hline
  \end{tabular}
  \caption{misses発言データ} \label{table:MissesRemark}
  \end{center}
\end{table}
まず，表\ref{table:FalseAlarmsRemark}の上段にあるような，議論の最初の方において意見を促すようなファシリテーターが行うような発言がfalseAlarmsとして誤判定されることが多かった．原因として過去に投稿された発言が少ないため他の発言との差が顕著になってしまったと考えられる．
\\
一方，表\ref{table:MissesRemark}の上段にあるような他の発言に対する雑談っぽさのある他の視点を提供しようとするような返信発言がmissesとして誤判定されることが多かった．原因として本研究における手法では返信関係にある２発言間の類似度は返信関係にない２発言間に比べて上がりやすくなっていることが考えられる．
\\
また，まとめを行う発言に弱いことが示された．原因としてまずはそもそも，表\ref{table:FalseAlarmsRemark}，\ref{table:MissesRemark}の両方にまとめを行う発言があるように人間でも時と場合によって判断が分かれることが挙げられる．既に投稿されたまとめ発言との差やタイミング等，提案手法で考慮しきれていない要素が人の判断に影響していると考える．
他の原因として，含まれている単語数が多いことが挙げられる．以前の発言に含まれている単語が集まっていることから，表\ref{table:FalseAlarmsRemark}の下段で示されているように偏り無く抽出されることや，逆に表\ref{table:MissesRemark}の下段で示されている発言のように偏った内容の抽出がされることがある．上記のような不確定要素が結果に影響を与えたと考える．

\section{結言}
\label{exp:conclusion}
本章では本研究で提案する話題変化の判定手法が有用であることを実験により確認した．伊藤孝行研究室の学生に，COLLAGREEで行われた議論データに対して基準を満たすと思われる発言にタグを付けてもらって評価データとした．評価実験では発言の内容に関係なく常に通知する手法と分散表現の代わりにTF-IDFを用いて発言をベクトル化する手法から比較した．

実験の結果，提案手法は適合率と再現率の偏りのない良いバランスを保つ結果を示すことが分かり，比較手法よりも高いF値を出すことがわかった．

 %-------------------------------------------------------------------------------
 \expandafter\ifx\csname MasterFile\endcsname\relax
	\def\BibFile{hoge}
	\input{../Bibliography/chapter}
  \fi
  %-------------------------------------------------------------------------------
  \expandafter\ifx\csname MasterFile\endcsname\relax
\end{document}
\fi
