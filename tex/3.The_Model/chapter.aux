\relax 
\citation{shi2015convolutional}
\citation{shi2015convolutional}
\@writefile{toc}{\contentsline {chapter}{\numberline {第3章}発言データの要約手法}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{model:chapter}{{3}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}序言}{1}}
\newlabel{model:introduction}{{3.1}{1}}
\citation{zhang2015deep}
\citation{shi2015convolutional}
\citation{shi2015convolutional}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}多チャンネル画像としてのマルチモーダル学習}{2}}
\newlabel{model:multi_channel}{{3.2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}複数モダリティの結合による多チャンネル画像の生成}{2}}
\newlabel{model:multi_channel_concat}{{3.2.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces 時空間データの例: 各時系列データは空間性を持つ}}{2}}
\newlabel{fig:the_model_spatiotemporal}{{3.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces 複数モダリティの結合}}{3}}
\newlabel{fig:the_model_multi_modal}{{3.2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces 複数チャンネルを持った画像としての3次元テンソル}}{3}}
\newlabel{fig:conv_lstm_tensor}{{3.3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces パッチの生成}}{4}}
\newlabel{fig:the_model_patch}{{3.4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Convolutional LSTMでのマルチモーダル学習}{4}}
\newlabel{model:conv_lstm}{{3.2.2}{4}}
\citation{zhang2015deep}
\newlabel{model:conv_lstm_norm}{{3.2.2}{5}}
\newlabel{model:conv_lstm_formula}{{3.2.2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces ConvLSTM層への局所正規化操作の導入}}{6}}
\newlabel{fig:the_model_conv_lstm_lrn}{{3.5}{6}}
\newlabel{eq:the_model_conv_lstm_prop1}{{3.1}{6}}
\newlabel{eq:the_model_conv_lstm_prop2}{{3.2}{7}}
\newlabel{eq:the_model_conv_lstm_prop3}{{3.3}{7}}
\citation{shi2015convolutional}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Encoding-Forecastingネットワーク}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces 拡張したConvLSTM層によるEncoding-Forecastingネットワーク}}{8}}
\newlabel{fig:the_model_encoding_forecasting}{{3.6}{8}}
\newlabel{eq:the_model_formula}{{3.4}{9}}
\citation{andrew2013deep}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}正準相関分析を取り入れたマルチモーダル学習}{10}}
\newlabel{model:dcca}{{3.3}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Sequence to SequenceモデルへのCCAの適用}{10}}
\newlabel{model:dcca_howto}{{3.3.1}{10}}
\newlabel{eq:model_dcca_objective}{{3.5}{11}}
\newlabel{eq:model_dcca_corr_approx}{{3.6}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}提案モデル1: DCCA ConvLSTM Model}{12}}
\newlabel{model:dcca_convlstm}{{3.3.2}{12}}
\newlabel{eq:model_dcca}{{3.7}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces DCCA ConvLSTM-seq2seq model}}{13}}
\newlabel{fig:model_dcca}{{3.7}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}提案モデル2: DCCA-Pretrain ConvLSTM Model}{13}}
\newlabel{model:dcca-pretrain_convlstm}{{3.3.3}{13}}
\newlabel{eq:model_dcca_pretrain}{{3.8}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces DCCA-Pretrain ConvLSTM-seq2seq model}}{14}}
\newlabel{fig:model_dcca_pretrain}{{3.8}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces DCCA-Pretrain ConvLSTM-seq2seq model}}{14}}
\newlabel{fig:model_dcca_finetune}{{3.9}{14}}
\citation{shi2015convolutional}
\bibstyle{jplain}
\bibdata{../Bibliography/database}
\newlabel{eq:model_dcca_finetune}{{3.9}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}結言}{15}}
\newlabel{model:conclusion}{{3.4}{15}}
